{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tijuana Results -- March 29, 2024\n",
    "\n",
    "Git: `2d5e2612b485b10055834a38af6a16dfa8f1dfad`\n",
    "\n",
    "To generate the cache/gpt2_happy_sad_03292024.json (~2500 prompt-adjective pairs\n",
    "with reps), I ran this command. \n",
    "\n",
    "```bash\n",
    "python3 scripts/get_value_reps.py \\\n",
    "    --adjective_json datasets/happy_sad_adjectives.json \\\n",
    "    --prompt_templates datasets/prompt_templates_03292024.json \\\n",
    "    --model_name gpt2 \\\n",
    "    --out_path cache/gpt2_happy_sad_03292024.json \n",
    "```\n",
    "\n",
    "To run the grok script, we'll run this command: \n",
    "\n",
    "```\n",
    "python scripts/grok_intrinsic_geometry.py \\\n",
    "    --plot-lr \\\n",
    "    --pca-components 20 \\\n",
    "    --knn-clusters 5\n",
    "```\n",
    "Results: \n",
    "The weights of the linear regression model trained on `happy_sad_adjectives.json` \n",
    "subbed into `prompt_templates_03292024.json` for predicting the valence \n",
    "(binary, +/-) can be found here: \n",
    "\n",
    "\n",
    "## Arousal Axis Discrimination Experiment\n",
    "```bash\n",
    "python3 scripts/get_value_reps.py \\\n",
    "    --adjective_json datasets/low_high_arousal_adjectives.json \\\n",
    "    --prompt_templates datasets/prompt_templates_03302024.json \\\n",
    "    --model_name gpt2 \\\n",
    "    --out_path cache/gpt2_low_high_arousal_03302024.json \n",
    "```\n",
    "\n",
    "```bash\n",
    "python scripts/grok_intrinsic_geometry.py \\\n",
    "    --plot-lr \\\n",
    "    --plot-all \\\n",
    "    --pca-components 20 \\\n",
    "    --knn-clusters 5 \\\n",
    "    --dataset-json cache/gpt2_low_high_arousal_03302024.json \\\n",
    "    --output-dir cache/arousal_results/\n",
    "```\n",
    "\n",
    "## Another Round of Valence Axis Discrimination\n",
    "```bash\n",
    "python3 scripts/get_value_reps.py \\\n",
    "    --adjective_json datasets/happy_sad_adjectives.json \\\n",
    "    --prompt_templates datasets/prompt_templates_03302024.json \\\n",
    "    --model_name gpt2 \\\n",
    "    --out_path cache/gpt2_happy_sad_03302024.json \n",
    "```\n",
    "\n",
    "```bash\n",
    "python scripts/grok_intrinsic_geometry.py \\\n",
    "    --plot-lr \\\n",
    "    --plot-all \\\n",
    "    --pca-components 20 \\\n",
    "    --knn-clusters 5 \\\n",
    "    --dataset-json cache/gpt2_happy_sad_03302024.json \\\n",
    "    --output-dir cache/happy_sad_03302024/\n",
    "```\n",
    "\n",
    "\n",
    "## 30 -> 254 Prompt Templates\n",
    "New dataset of prompts in `datasets/prompt_templates_0330b2024.json`\n",
    "### Valence Axis (254 Prompt Templates)\n",
    "```bash\n",
    "python3 scripts/get_value_reps.py \\\n",
    "    --adjective_json datasets/happy_sad_adjectives.json \\\n",
    "    --prompt_templates datasets/prompt_templates_0330b2024.json \\\n",
    "    --model_name gpt2 \\\n",
    "    --out_path cache/gpt2_happy_sad_0330b2024.json \n",
    "```\n",
    "\n",
    "```bash\n",
    "python scripts/grok_intrinsic_geometry.py \\\n",
    "    --plot-lr \\\n",
    "    --plot-all \\\n",
    "    --pca-components 20 \\\n",
    "    --knn-clusters 5 \\\n",
    "    --dataset-json cache/gpt2_happy_sad_0330b2024.json \\\n",
    "    --output-dir cache/happy_sad_0330b2024/\n",
    "```\n",
    "\n",
    "### Arousal Axis (254 Prompt Templates)\n",
    "```bash\n",
    "python3 scripts/get_value_reps.py \\\n",
    "    --adjective_json datasets/low_high_arousal_adjectives.json \\\n",
    "    --prompt_templates datasets/prompt_templates_0330b2024.json \\\n",
    "    --model_name gpt2 \\\n",
    "    --out_path cache/gpt2_low_high_arousal_0330b2024.json \n",
    "```\n",
    "\n",
    "```bash\n",
    "python scripts/grok_intrinsic_geometry.py \\\n",
    "    --plot-lr \\\n",
    "    --plot-all \\\n",
    "    --pca-components 20 \\\n",
    "    --knn-clusters 5 \\\n",
    "    --dataset-json cache/gpt2_low_high_arousal_0330b2024.json \\\n",
    "    --output-dir cache/low_high_arousal_0330b2024/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of happy sad adjectives 2\n",
      "Length of arousal adjectives 2\n",
      "Length of templates march 29th 14\n",
      "Length of templates march 30th 30\n",
      "Length of templates march 30th 254\n"
     ]
    }
   ],
   "source": [
    "happy_sad_adjective_path = '../datasets/happy_sad_adjectives.json'\n",
    "# load json, print length\n",
    "import json\n",
    "with open(happy_sad_adjective_path, 'r') as f:\n",
    "    happy_sad_adjectives = json.load(f)\n",
    "print(\"Length of happy sad adjectives\", len(happy_sad_adjectives)) # 1000\n",
    "\n",
    "\n",
    "# Sanity check on the data \n",
    "arousal_adj_path = '../datasets/low_high_arousal_adjectives.json'\n",
    "# load json, print length \n",
    "with open(arousal_adj_path, 'r') as f:\n",
    "    arousal_adj = json.load(f)\n",
    "print(\"Length of arousal adjectives\", len(arousal_adj)) # 1000\n",
    "\n",
    "templates_29_path = '../datasets/prompt_templates_03292024.json'\n",
    "# load json, print length\n",
    "with open(templates_29_path, 'r') as f:\n",
    "    templates_29 = json.load(f)\n",
    "\n",
    "print(\"Length of templates march 29th\", len(templates_29)) # 1000\n",
    "\n",
    "templates_30_path = '../datasets/prompt_templates_03302024.json'\n",
    "# load json, print length\n",
    "with open(templates_30_path, 'r') as f:\n",
    "    templates_30 = json.load(f)\n",
    "print(\"Length of templates march 30th\", len(templates_30)) # 1000\n",
    "\n",
    "templates_30b_path = '../datasets/prompt_templates_0330b2024.json'\n",
    "with open(templates_30b_path, 'r') as f:\n",
    "    templates_30b = json.load(f)\n",
    "print(\"Length of templates march 30th\", len(templates_30b)) # 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valence-Arousal Axes Hack\n",
    "\n",
    "Let us use the learned weights from `cache/happy_sad_0330b2024/weights.npz` \n",
    "and `cache/low_high_arousal_0330b2024/weights.npz` along with the activations \n",
    "from `cache/gpt2_happy_sad_0330b2024.json` to make a valence-arousal axis. \n",
    " 1. Load weights for valence (happy_sad) and arousal (low_high_arousal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9216)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "valence_weight_path = '../cache/happy_sad_0330b2024/weights.npz'\n",
    "arousal_weight_path = '../cache/low_high_arousal_0330b2024/weights.npz'\n",
    "\n",
    "import numpy as np\n",
    "valence_weights = np.load(valence_weight_path)\n",
    "arousal_weights = np.load(arousal_weight_path)\n",
    "\n",
    "valence_weight_vec = valence_weights['arr_0']\n",
    "valence_bias = valence_weights['arr_1']\n",
    "\n",
    "arousal_weight_vec = arousal_weights['arr_0']\n",
    "arousal_bias = arousal_weights['arr_1']\n",
    "\n",
    "# TODO: load the latent reps from cache/gpt2_happy_sad_0330b2024.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
