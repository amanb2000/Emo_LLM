{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2 Adjective Representation PCA\n",
    "\n",
    "Let's look at the representations induced in a noun after being described by various adjectives. \n",
    "\n",
    "We will sample adjectives from Webster's dictionary, and we will use a pre-defined single-token noun/prompt for now. \n",
    "\n",
    "An exciting extension for understanding the **temporality** of emotion in LLMs by examining structure in the representations of the noun after T tokens have passed. Will the strength of the \"emotion signals\" dissapate over time? Will we see commonality in the representations when projected along an \"emotional access\" (PCA dimension)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GPT-2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.237336158752441\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: What is the model loss on this sample input sentence? \n",
    "input_str = \"Bob is extremely abashed. Therefore, Bob\" \n",
    "input_ids = tokenizer.encode(input_str, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "# Generate the output\n",
    "output = model(input_ids, labels=input_ids)\n",
    "loss = output.loss\n",
    "print(\"Loss: \", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Webster's Dictionary\n",
    "\n",
    "We are going to pull the [Webster's Unabridged Dictionary](https://www.gutenberg.org/ebooks/29765)\n",
    "from project Gutenberg and parse it to find adjectives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = {\n",
    "  \"happy_adjectives\": [\n",
    "    \"joyful\", \"cheerful\", \"radiant\", \"blissful\", \"upbeat\", \"elated\", \"jubilant\", \"gleeful\", \"ecstatic\", \"sunny\",\n",
    "    \"buoyant\", \"lively\", \"vibrant\", \"optimistic\", \"sanguine\", \"content\", \"satisfied\", \"delighted\", \"overjoyed\", \"enthused\",\n",
    "    \"exuberant\", \"euphoric\", \"animated\", \"spirited\", \"glowing\", \"sparkling\", \"beaming\", \"luminous\", \"bright\", \"brilliant\",\n",
    "    \"energetic\", \"zesty\", \"bubbly\", \"peppy\", \"refreshed\", \"rejuvenated\", \"invigorated\", \"stimulated\", \"thrilled\", \"excited\",\n",
    "    \"happy\", \"grateful\", \"appreciative\", \"blessed\", \"fortunate\", \"lucky\", \"charmed\", \"enchanted\", \"merry\", \"jolly\",\n",
    "    \"festive\", \"celebratory\", \"hearty\", \"welcoming\", \"genial\", \"friendly\", \"warm\", \"loving\", \"affectionate\", \"kind\",\n",
    "    \"gentle\", \"tender\", \"compassionate\", \"caring\", \"considerate\", \"sympathetic\", \"understanding\", \"supportive\", \"encouraging\", \"motivating\",\n",
    "    \"inspiring\", \"uplifting\", \"empowering\", \"positive\", \"hopeful\", \"confident\", \"assured\", \"secure\", \"safe\", \"protected\",\n",
    "    \"peaceful\", \"calm\", \"serene\", \"tranquil\", \"relaxed\", \"easygoing\", \"carefree\", \"untroubled\", \"contented\", \"satisfied\"\n",
    "  ],\n",
    "  \"sad_adjectives\": [\n",
    "    \"sad\", \"unhappy\", \"sorrowful\", \"miserable\", \"dejected\", \"depressed\", \"downcast\", \"gloomy\", \"dismal\", \"bleak\",\n",
    "    \"despondent\", \"disheartened\", \"hopeless\", \"discouraged\", \"dispirited\", \"downhearted\", \"melancholy\", \"morose\", \"woeful\", \"doleful\",\n",
    "    \"pained\", \"hurt\", \"wounded\", \"afflicted\", \"troubled\", \"distressed\", \"anguished\", \"tormented\", \"plagued\", \"burdened\",\n",
    "    \"weighed down\", \"oppressed\", \"besieged\", \"bitter\", \"resentful\", \"discontented\", \"dissatisfied\", \"frustrated\", \"annoyed\", \"irritated\",\n",
    "    \"angry\", \"furious\", \"raging\", \"livid\", \"indignant\", \"outraged\", \"scornful\", \"disgusted\", \"repulsed\", \"sickened\",\n",
    "    \"disappointed\", \"let down\", \"betrayed\", \"abandoned\", \"forsaken\", \"neglected\", \"ignored\", \"overlooked\", \"undervalued\", \"unappreciated\",\n",
    "    \"insecure\", \"vulnerable\", \"exposed\", \"fragile\", \"weak\", \"feeble\", \"powerless\", \"helpless\", \"defenseless\", \"submissive\",\n",
    "    \"timid\", \"shy\", \"introverted\", \"withdrawn\", \"reclusive\", \"isolated\", \"lonely\", \"alone\", \"alienated\", \"estranged\",\n",
    "    \"pessimistic\", \"cynical\", \"skeptical\", \"doubtful\", \"wary\", \"cautious\", \"guarded\", \"reserved\", \"tense\", \"anxious\",\n",
    "    \"worried\", \"fearful\", \"terrified\", \"horrified\", \"apprehensive\", \"nervous\", \"panicked\", \"alarmed\", \"shocked\", \"startled\"\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joyful',\n",
       " 'cheerful',\n",
       " 'radiant',\n",
       " 'blissful',\n",
       " 'upbeat',\n",
       " 'elated',\n",
       " 'jubilant',\n",
       " 'gleeful',\n",
       " 'ecstatic',\n",
       " 'sunny']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjectives = adj[\"happy_adjectives\"] + adj[\"sad_adjectives\"]\n",
    "adjectives[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation \n",
    "\n",
    "Let's format it as something like a statement of fact about \"James\"\n",
    "\n",
    "```\n",
    "Bob is extremely abderian. Therefore, Bob \n",
    "                   {adjective}       {examine these representations}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template_string = \"Alice is extremely {}. Therefore, Alice\"\n",
    "template_string = \"Bob is extremely {}, so Bob\"\n",
    "\n",
    "# generate a sentence for each adjective\n",
    "sentences = [template_string.format(x) for x in adjectives]\n",
    "\n",
    "# tokenize the sentences \n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "input_ids = tokenizer(sentences, \n",
    "                      return_tensors=\"pt\", \n",
    "                      padding=True, \n",
    "                      truncation=True, \n",
    "                      max_length=128, \n",
    "                      add_special_tokens=True, \n",
    "                      return_attention_mask=True)\n",
    "input_ids.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18861,   318,  4457, 48977,    11,   523,  5811,  -100,  -100,  -100],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's add the labels to the input_ids dictionary -- \n",
    "# we want to predict the input_ids, but set -100 if it's a padding (eos) token \n",
    "input_ids['labels'] = input_ids.input_ids.clone()\n",
    "input_ids['labels'][input_ids['labels'] == tokenizer.eos_token_id] = -100\n",
    "input_ids['labels'] = input_ids['labels'].to('cuda')\n",
    "\n",
    "input_ids['labels'][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected sentences:  190\n",
      "Number of adjectives:  190\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of selected sentences: \", input_ids['input_ids'].shape[0])\n",
    "print(\"Number of adjectives: \", len(adjectives))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter for the low CE loss adjectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:01<00:00, 110.29it/s]\n"
     ]
    }
   ],
   "source": [
    "ce_losses = [] \n",
    "\n",
    "for i in tqdm(range(input_ids['input_ids'].shape[0])):\n",
    "    input_id = input_ids['input_ids'][i].unsqueeze(0).to('cuda')\n",
    "    attention_mask = input_ids['attention_mask'][i].unsqueeze(0).to('cuda')\n",
    "    labels = input_ids['labels'][i].unsqueeze(0).to('cuda')\n",
    "    output = model(input_id, attention_mask=attention_mask, labels=labels)\n",
    "    ce_losses.append(output.loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ce_losses = np.array(ce_losses)\n",
    "plt.hist(ce_losses, bins=100)\n",
    "plt.title(\"Histogram of cross-entropy losses on the selected sentences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of adjectives: 721\n"
     ]
    }
   ],
   "source": [
    "# filter adjectives, input_ids, attention_mask, and labels \n",
    "# using the low_loss_mask\n",
    "adjectives_filtered = [adjectives[i] for i in range(len(adjectives)) if low_loss_mask[i]]\n",
    "input_ids['input_ids'] = input_ids['input_ids'][low_loss_mask]\n",
    "input_ids['attention_mask'] = input_ids['attention_mask'][low_loss_mask]\n",
    "input_ids['labels'] = input_ids['labels'][low_loss_mask]\n",
    "\n",
    "print(f\"Length of adjectives: {len(adjectives_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bob_vals(past_kvs): \n",
    "    \"\"\"\n",
    "    Args: \n",
    "        `past_kvs`: model output['past_key_values'] from running a batch of \n",
    "        left-padded sentences through the model.\n",
    "\n",
    "        Accepts `past_kvs`, a tuple of length NUM_LAYERS (32), each containing a \n",
    "        2-long tuple (for keys and values respectively), each containing a torch \n",
    "        Tensor of shape [batch, num_heads, seq_len, head_dim] (for values). \n",
    "\n",
    "    Returns: \n",
    "        `bob_kvs`: list of length BATCH_SIZE with some numpy arrays representing \n",
    "        of shape [num_layers, num_heads, head_dim]\n",
    "    \"\"\"\n",
    "\n",
    "    # iterate thru batch size \n",
    "    BATCH_SIZE = past_kvs[0][1].shape[0]\n",
    "\n",
    "    batch_bob_values = []\n",
    "    for batch_el in range(BATCH_SIZE): \n",
    "        # aggregate representations from across the layers \n",
    "        bob_numpy_arrays = []\n",
    "        for layer in range(len(past_kvs)): \n",
    "            bob_layer_l_value = past_kvs[layer][1][batch_el, :, -1, :].detach().cpu().numpy()\n",
    "            # print(\"Bob layer_l_value shape: \", bob_layer_l_value.shape)\n",
    "\n",
    "            # unsqueeze on dimension zero\n",
    "            bob_numpy_arrays.append(bob_layer_l_value[np.newaxis, ...])\n",
    "        \n",
    "        # merge on axis 0\n",
    "        bob_numpy_arrays_conc = np.concatenate(bob_numpy_arrays, axis=0)\n",
    "        # print(\"Bob numpy arrays shape (post-concatenation to combine layers)\", bob_numpy_arrays_conc.shape)\n",
    "        # bob_numpy_arrays now has shape n_layers = 32, n_heads = 8, embed_dim=128\n",
    "\n",
    "        # add it to the list\n",
    "        batch_bob_values.append(bob_numpy_arrays_conc)\n",
    "\n",
    "\n",
    "    return batch_bob_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Bob representations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:02<00:00, 93.13it/s, loss=6.2003403]\n"
     ]
    }
   ],
   "source": [
    "# iterate thru input_ids\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "past_values_bob = [] # list of length NUM_ADJECTIVES, each element is\n",
    "                     # a numpy array of bob value reps of shape [num_layers=32, n_heads=8, embed_dim=128]\n",
    "\n",
    "losses = []\n",
    "\n",
    "print(\"Generating Bob representations...\")\n",
    "# pbar = tqdm(total=len(input_ids[\"input_ids\"]) // BATCH_SIZE + 1)\n",
    "pbar = tqdm(range(len(input_ids[\"input_ids\"]) // BATCH_SIZE))\n",
    "for i in pbar:\n",
    "    batch_ids = input_ids[\"input_ids\"][i * BATCH_SIZE: (i + 1) * BATCH_SIZE].to(model.device)\n",
    "    batch_attn = input_ids[\"attention_mask\"][i * BATCH_SIZE: (i + 1) * BATCH_SIZE].to(model.device)[:, :]\n",
    "    batch_labels = input_ids[\"labels\"][i * BATCH_SIZE: (i + 1) * BATCH_SIZE].to(model.device)\n",
    "    # print(\"Batch ids shape (batch, ): \", batch_ids.shape)\n",
    "    # print(\"Input string: \", tokenizer.decode(batch_ids[15, :]))\n",
    "    # print(f\"Final token: `{tokenizer.decode(batch_ids[0, -1:])}`\")\n",
    "    outputs = model.forward(batch_ids, return_dict=True, labels=batch_labels, attention_mask=batch_attn)\n",
    "    # print(\"Output keys: \", outputs.keys())\n",
    "\n",
    "    past_kvs = outputs['past_key_values']\n",
    "\n",
    "    # print(\"Past key values (n_layers): \", len(past_kvs))\n",
    "    # print(\"Batch size (reconstructed): \", past_kvs[0][1].shape[0])\n",
    "    bob_numpy_arrays = get_bob_vals(past_kvs) # [batch_size], each a numpy array of shape [num_layers=32, n_heads=8, embed_dim=128]\n",
    "\n",
    "    # let's add this to the past_values_bob \n",
    "    past_values_bob += bob_numpy_arrays\n",
    "\n",
    "\n",
    "    # storing the loss value\n",
    "    loss = outputs['loss'].detach().cpu().numpy()\n",
    "    losses.append(loss)\n",
    "\n",
    "    # update with loss value\n",
    "    pbar.set_postfix({\"loss\": loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bob is extremely cheerful, so Bob<|endoftext|><|endoftext|><|endoftext|>',\n",
       " 'Bob is extremely radiant, so Bob<|endoftext|><|endoftext|><|endoftext|>',\n",
       " 'Bob is extremely blissful, so Bob<|endoftext|><|endoftext|>',\n",
       " 'Bob is extremely upbeat, so Bob<|endoftext|><|endoftext|><|endoftext|>',\n",
       " 'Bob is extremely elated, so Bob<|endoftext|><|endoftext|>',\n",
       " 'Bob is extremely jubilant, so Bob<|endoftext|>',\n",
       " 'Bob is extremely gleeful, so Bob<|endoftext|><|endoftext|>',\n",
       " 'Bob is extremely ecstatic, so Bob<|endoftext|><|endoftext|><|endoftext|>',\n",
       " 'Bob is extremely sunny, so Bob<|endoftext|><|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(input_ids['input_ids'][1:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bob representations:  190\n",
      "Number of adjectives:  190\n",
      "Shape of individual bob value representation:  (12, 12, 64)\n",
      "\t[num_layers=32, n_heads=8, embed_dim=128]\n",
      "Length of losses:  190\n",
      "Loss[0]:  6.3260303\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of bob representations: \", len(past_values_bob))\n",
    "print(\"Number of adjectives: \", len(adjectives))\n",
    "print(\"Shape of individual bob value representation: \", past_values_bob[0].shape)\n",
    "print(\"\\t[num_layers=32, n_heads=8, embed_dim=128]\")\n",
    "print(\"Length of losses: \", len(losses))\n",
    "print(\"Loss[0]: \", losses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of past_values_bob:  190\n",
      "Shape of past_values_bob[0]:  (12, 12, 64)\n",
      "Length of losses:  190\n"
     ]
    }
   ],
   "source": [
    "print(\"Len of past_values_bob: \", len(past_values_bob))\n",
    "print(\"Shape of past_values_bob[0]: \", past_values_bob[0].shape)\n",
    "print(\"Length of losses: \", len(losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA on Bob Representations\n",
    "\n",
    "Gotta flatten the past_values_bob[i] value reps, make a big ole matrix, and do \n",
    "PCA on it, and hope my computer doesn't explode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past values bob matrix shape (num_adjectives, token_value_dim):  (190, 9216)\n"
     ]
    }
   ],
   "source": [
    "flat_past_values_bob = []\n",
    "NUM_LAYERS = 5 # take reps from the first NUM_LAYERS layers\n",
    "\n",
    "for i in range(len(past_values_bob)): \n",
    "    flat_past_values_bob.append(past_values_bob[i][:, :, :].flatten())\n",
    "\n",
    "past_values_bob_matrix = np.array(flat_past_values_bob)\n",
    "print(\"Past values bob matrix shape (num_adjectives, token_value_dim): \", past_values_bob_matrix.shape)\n",
    "\n",
    "# save to disk \n",
    "np.save(\"bob_representations_flat.npy\", past_values_bob_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_filtered = losses\n",
    "past_values_bob_matrix_filtered = past_values_bob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999994"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize each bob representation (by row)\n",
    "past_values_bob_matrix_filtered_normalized = past_values_bob_matrix_filtered / np.linalg.norm(past_values_bob_matrix_filtered, axis=1)[:, np.newaxis]\n",
    "\n",
    "np.linalg.norm(past_values_bob_matrix_filtered_normalized[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adjectives_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43madjectives_filtered\u001b[49m[:\u001b[38;5;241m10\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adjectives_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "adjectives_filtered[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data shape: (190, 3)\n",
      "First 3-dimensional representation: [-0.0083049   0.01197359  0.045966  ]\n"
     ]
    }
   ],
   "source": [
    "# doing pca \n",
    "# Initialize PCA to keep the first 3 principal components\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "# Fit PCA on your data and transform it to get the 3-dimensional representation\n",
    "transformed_data = pca.fit_transform(past_values_bob_matrix_filtered_normalized)\n",
    "\n",
    "# transformed_data now has shape [N, 3], where N is the number of examples\n",
    "print(\"Transformed data shape:\", transformed_data.shape)\n",
    "print(\"First 3-dimensional representation:\", transformed_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 721 samples in 0.003s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed neighbors for 721 samples in 0.541s...\n",
      "[t-SNE] Computed conditional probabilities for sample 721 / 721\n",
      "[t-SNE] Mean sigma: 0.030498\n",
      "[t-SNE] KL divergence after 50 iterations with early exaggeration: 61.516678\n",
      "[t-SNE] KL divergence after 300 iterations: 0.908133\n",
      "TSNE results shape: (721, 3)\n",
      "First 3-dimensional representation: [ 7.2493596  0.6732346 10.581374 ]\n"
     ]
    }
   ],
   "source": [
    "# aldo run a t-sne\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=3, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(past_values_bob_matrix_filtered_normalized)\n",
    "\n",
    "# tsne_results now has shape [N, 3], where N is the number of examples\n",
    "print(\"TSNE results shape:\", tsne_results.shape)\n",
    "print(\"First 3-dimensional representation:\", tsne_results[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotly Interactive Scatter Plot\n",
    "\n",
    "We will output this as an HTML file you can view with the browser to explore the \n",
    "data space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create a list of colors that scales with the losses \n",
    "final_losses = losses_filtered\n",
    "final_data = transformed_data\n",
    "final_adjectives = adjectives\n",
    "\n",
    "\n",
    "colors = np.array(final_losses) - np.min(final_losses)\n",
    "colors = colors / np.max(colors)\n",
    "\n",
    "\n",
    "# Create a 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=final_data[:, 0],\n",
    "    y=final_data[:, 1],\n",
    "    z=final_data[:, 2],\n",
    "    text=final_adjectives,  # Set the labels for each point\n",
    "    mode='markers+text',  # Choose to have both markers and text\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color=colors,  # Set the color of each point\n",
    "        opacity=0.8\n",
    "    )\n",
    ")])\n",
    "\n",
    "# Customize the layout of the plot\n",
    "fig.update_layout(\n",
    "    title=f'GPT-2, Happy/Sad: PCA on Bob reps in \"Bob is extremely <adjective>. Therefore <Bob>\" sentences',\n",
    "    scene=dict(\n",
    "        xaxis_title='PC1',\n",
    "        yaxis_title='PC2',\n",
    "        zaxis_title='PC3'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Export the plot as an HTML file\n",
    "fig.write_html('bob_happy_sad.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot for t-sne\n",
    "# Create a 3D scatter plot\n",
    "\n",
    "final_tsne_data = tsne_results\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=final_tsne_data[:, 0],\n",
    "    y=final_tsne_data[:, 1],\n",
    "    z=final_tsne_data[:, 2],\n",
    "    text=final_adjectives,  # Set the labels for each point\n",
    "    mode='markers+text',  # Choose to have both markers and text\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color=colors,  # Set the color of each point\n",
    "        opacity=0.8\n",
    "    )\n",
    ")])\n",
    "\n",
    "# Customize the layout of the plot\n",
    "fig.update_layout(\n",
    "    title=f'Mistral 7b, top {len(final_losses)}: T-SNE on Bob reps in \"Bob is extremely <adjective>. Therefore <Bob>\" sentences',\n",
    "    scene=dict(\n",
    "        xaxis_title='PC1',\n",
    "        yaxis_title='PC2',\n",
    "        zaxis_title='PC3'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Export the plot as an HTML file\n",
    "fig.write_html('bob_adjective_reps_tsne.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
