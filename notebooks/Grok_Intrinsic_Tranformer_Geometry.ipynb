{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fc32016-8ecb-4b1d-b2e5-ef55df0402cb",
   "metadata": {},
   "source": [
    "# Grokking LLM Emotional Latent Space in Human Interpretable Dimensions\n",
    "### Parsing LLM emptional latent space dataset.\n",
    "### This is the notebook version of ../scripts/grok_intrinsic_geometry.py\n",
    "### cayden, Aman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2249c676-2f30-465e-9e21-847d2a04514b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data JSON...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../cache/gpt2_low_high_arousal_0330b2024.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m json_file_path \u001b[38;5;241m=\u001b[39m DATASET_JSON\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading training data JSON...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     25\u001b[0m     latent_space_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n",
      "File \u001b[0;32m~/devdir/Emo_LLM/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../cache/gpt2_low_high_arousal_0330b2024.json'"
     ]
    }
   ],
   "source": [
    "USE_PCA = False\n",
    "PLOT_LR = True\n",
    "PLOT_ALL_DATA = True\n",
    "PCA_COMPONENTS = 20\n",
    "KNN_CLUSTERS = 5\n",
    "TOTAL_LAYERS = 12\n",
    "OUTPUT_DIR = \"../cache/low_high_arousal_0330b2024\"\n",
    "DATASET_JSON = \"../cache/gpt2_low_high_arousal_0330b2024.json\"\n",
    "MODEL_NAME = \"gpt2\"\n",
    "\n",
    "# SETUP\n",
    "if USE_PCA:\n",
    "    print(\"Using PCA, thus PLOT_LR will not run.\")\n",
    "    \n",
    "# make output-dir if it doesn't exist. Confirm overwrite if it existsyy\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "        \n",
    "# open data file\n",
    "latent_space_data = None\n",
    "json_file_path = DATASET_JSON\n",
    "print(\"Loading training data JSON...\")\n",
    "\n",
    "with open(json_file_path, 'r') as file:\n",
    "    latent_space_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df0b39ca-17c7-46d1-b73c-31b1feef5ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "import json\n",
    "import random\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import argparse\n",
    "import pdb\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6470da47-33bb-4645-9d3b-9a6f5d56c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All helper functions\n",
    "\n",
    "def load_and_split_data(data, train_ratio=0.6, e1_ratio=0.15, e2_ratio=0.15, e3_ratio=0.1):\n",
    "    # get all the possible adjectives prompts in the dataset\n",
    "    all_adjectives = list(set(entry['adjective'] for entry in data))\n",
    "    print(\"all_adjectives\")\n",
    "    print(all_adjectives)\n",
    "    all_prompts = list(set(entry['prompt_template'] for entry in data))\n",
    "    print(\"all_prompts\")\n",
    "    print(all_prompts)\n",
    "\n",
    "    # get the size of each eval set\n",
    "    # SLOW PART STARTS HERE>>>\n",
    "    # e1_size_adj = int(len(all_adjectives) * e1_ratio)\n",
    "    # e2_size_prompts = int(len(all_prompts) * e2_ratio)\n",
    "    # e3_size = int(len(data) * e3_ratio)\n",
    "    # # get the special adjectives/prompts to hold out for evals\n",
    "    # e1_adjs = random.sample(all_adjectives, e1_size_adj)\n",
    "    # e2_prompts = random.sample(all_prompts, e2_size_prompts)\n",
    "    # e3_objs = random.sample(data, e3_size)\n",
    "\n",
    "    # # make those eval sets\n",
    "    # E1_set = [entry for entry in data if entry['adjective'] in e1_adjs]\n",
    "    # E2_set = [entry for entry in data if entry['prompt_template'] in e2_prompts]\n",
    "    # E3_set = [entry for entry in data if entry in e3_objs]\n",
    "    # get the size of each eval set\n",
    "    e1_size_adj = int(len(all_adjectives) * e1_ratio)\n",
    "    e2_size_prompts = int(len(all_prompts) * e2_ratio)\n",
    "    e3_size = int(len(data) * e3_ratio)\n",
    "\n",
    "    # get the special adjectives/prompts to hold out for evals\n",
    "    e1_adjs = random.sample(all_adjectives, e1_size_adj)\n",
    "    e2_prompts = random.sample(all_prompts, e2_size_prompts)\n",
    "    e3_objs = random.sample(data, e3_size)\n",
    "\n",
    "    # make those eval sets and training set in a single pass\n",
    "    E1_set = []\n",
    "    E2_set = []\n",
    "    E3_set = []\n",
    "    train_set = []\n",
    "\n",
    "    for entry in data:\n",
    "        if entry['adjective'] in e1_adjs:\n",
    "            E1_set.append(entry)\n",
    "        elif entry['prompt_template'] in e2_prompts:\n",
    "            E2_set.append(entry)\n",
    "        elif entry in e3_objs:\n",
    "            E3_set.append(entry)\n",
    "        else:\n",
    "            train_set.append(entry)\n",
    "\n",
    "    # training data is what's left over\n",
    "    # remaining_data = [entry for entry in data if entry not in E1_set + E2_set + E3_set]\n",
    "    # train_size = int(len(remaining_data) * train_ratio)\n",
    "    # train_set = random.sample(remaining_data, train_size)\n",
    "    train_size = int(len(train_set) * train_ratio)\n",
    "    train_set = random.sample(train_set, train_size)\n",
    "\n",
    "    print(\"Initial dataset size: \", len(data))\n",
    "    print(\"Training set size: \", len(train_set))\n",
    "    print(\"E1 set size: \", len(E1_set))\n",
    "    print(\"E2 set size: \", len(E2_set))\n",
    "    print(\"E3 set size: \", len(E3_set))\n",
    "\n",
    "    print(\"--- Data loaded.\")\n",
    "    # SLOW PART ENDS HERE <<<\n",
    "    return train_set, E1_set, E2_set, E3_set\n",
    "\n",
    "def extract_features_labels(data, layers_to_use=None):\n",
    "    \"\"\"\n",
    "    Extract features and labels from the data.\n",
    "\n",
    "    Parameters:\n",
    "    - data: The dataset containing latent vectors and labels.\n",
    "    - layers_to_use: Optional list of integers specifying which transformer layers to use. If None, all layers are used.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple of (features, labels), where features is a NumPy array of the flattened selected layers and labels is a NumPy array of the binary labels.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for item in data:\n",
    "        latent_vectors = item['latent_space']\n",
    "\n",
    "        if layers_to_use is not None:\n",
    "            # Filter the latent vectors to only include the specified layers\n",
    "            latent_vectors = [latent_vectors[i] for i in layers_to_use]\n",
    "\n",
    "        # Flatten the selected layers into a single list for each data entry\n",
    "        # Adjust flattening to account for the two levels of nesting now\n",
    "        flattened_vector = [val for layer in latent_vectors for head in layer for val in head]\n",
    "\n",
    "        features.append(flattened_vector)\n",
    "        labels.append(1 if item['class_0_true'] else 0)\n",
    "\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "def preprocess_features(features, mean=None, scale=None, pca_model=None, use_pca=False):\n",
    "    # Initialize the scaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit or apply normalization\n",
    "    if mean is None:\n",
    "        normalized_features = scaler.fit_transform(features)\n",
    "        mean = scaler.mean_\n",
    "        scale = scaler.scale_\n",
    "    else:\n",
    "        scaler.mean_ = mean\n",
    "        scaler.scale_ = scale\n",
    "        normalized_features = scaler.transform(features)\n",
    "\n",
    "    # Apply PCA if enabled\n",
    "    if use_pca:\n",
    "        if pca_model is None:\n",
    "            pca_model = PCA(n_components=PCA_COMPONENTS)\n",
    "            pca_features = pca_model.fit_transform(normalized_features)\n",
    "        else:\n",
    "            pca_features = pca_model.transform(normalized_features)\n",
    "        return pca_features, mean, scale, pca_model\n",
    "    else:\n",
    "        return normalized_features, mean, scale, None\n",
    "\n",
    "def train_lr_classifier(features, labels):\n",
    "    classifier = LogisticRegression(max_iter=1000)\n",
    "    classifier.fit(features, labels)\n",
    "    return classifier\n",
    "\n",
    "def test_lr_classifier(classifier, features, labels, out_path = None):\n",
    "    y_pred = classifier.predict(features)\n",
    "    classification_report_ = classification_report(labels, y_pred)\n",
    "    print(\"Classification Report:\\n\", classification_report_)\n",
    "\n",
    "    if out_path is not None: \n",
    "        out_path = os.path.join(out_path)\n",
    "        with open(out_path, 'w') as f: \n",
    "            f.write(classification_report_)\n",
    "\n",
    "def train_knn_classifier(features, labels, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Train a K-Nearest Neighbors classifier with the given features and labels.\n",
    "\n",
    "    Parameters:\n",
    "    - features: The feature matrix for training data.\n",
    "    - labels: The label vector for training data.\n",
    "    - n_neighbors: The number of neighbors to use for k-nearest neighbors voting.\n",
    "\n",
    "    Returns:\n",
    "    - The trained KNN classifier.\n",
    "    \"\"\"\n",
    "    classifier = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    classifier.fit(features, labels)\n",
    "    return classifier\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    \"\"\"\n",
    "    Sanitizes a string to be safe for use as a filename by removing or replacing characters\n",
    "    that are not allowed or recommended in Windows and UNIX/Linux filesystems.\n",
    "    \n",
    "    Args:\n",
    "    filename (str): The original filename string to sanitize.\n",
    "    \n",
    "    Returns:\n",
    "    str: A sanitized version of the filename.\n",
    "    \"\"\"\n",
    "    # Remove characters that are invalid for Windows or UNIX/Linux filesystems\n",
    "    sanitized = re.sub(r'[<>:\"/\\\\|?*\\x00-\\x1F]', '', filename)\n",
    "    # Replace leading and trailing periods and spaces (Windows)\n",
    "    sanitized = re.sub(r'^[. ]+', '', sanitized)\n",
    "    sanitized = re.sub(r'[. ]+$', '', sanitized)\n",
    "    # Replace multiple consecutive spaces with a single space\n",
    "    sanitized = re.sub(r' +', ' ', sanitized)\n",
    "    # Ensure the filename is not too long\n",
    "    sanitized = sanitized[:255]\n",
    "    return sanitized\n",
    "\n",
    "def test_knn_classifier(classifier, features, labels, out_path = None):\n",
    "    \"\"\"\n",
    "    Test (evaluate) the trained K-Nearest Neighbors classifier on a test dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - classifier: The trained KNN classifier.\n",
    "    - features: The feature matrix for test data.\n",
    "    - labels: The label vector for test data.\n",
    "\n",
    "    Prints:\n",
    "    - Classification report including precision, recall, and F1-score.\n",
    "    \"\"\"\n",
    "    y_pred = classifier.predict(features)\n",
    "    classification_report_ = classification_report(labels, y_pred)\n",
    "    print(\"Classification Report:\\n\", classification_report_)\n",
    "    if out_path is not None:\n",
    "        with open(out_path, 'w') as f: \n",
    "            f.write(classification_report_)\n",
    "\n",
    "def plot_3d_pca(data, labels, adjectives=None, output_dir = None, prompt=\"\"):\n",
    "    # Normalize labels for color scaling\n",
    "    colors = np.array(labels) - np.min(labels)\n",
    "    colors = colors / np.max(colors)\n",
    "    \n",
    "    # Create a 3D scatter plot\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=data[:, 0],\n",
    "        y=data[:, 1],\n",
    "        z=data[:, 2],\n",
    "        text=adjectives,  # Use adjectives as markers' text\n",
    "        mode='markers+text',  # Display both markers and text\n",
    "        marker=dict(\n",
    "            size=5,\n",
    "            color=colors,  # Use normalized labels for color\n",
    "            opacity=0.8\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    # Customize layout\n",
    "    fig.update_layout(\n",
    "        title=f'3D PCA Visualization, prompt={prompt}',\n",
    "        scene=dict(\n",
    "            xaxis_title='PC1',\n",
    "            yaxis_title='PC2',\n",
    "            zaxis_title='PC3'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Show plot in notebook or export as desired\n",
    "    fig.show()\n",
    "    # To export to HTML, uncomment the following line:\n",
    "    # fig.write_html('3d_pca_visualization.html')\n",
    "    if output_dir: \n",
    "        out_path = os.path.join(output_dir, f\"3d_pca_visualization{sanitize_filename(prompt)}.html\")\n",
    "        print(\"OUTPUT PATH FOR PCA: \", out_path)\n",
    "        fig.write_html(out_path)\n",
    "\n",
    "def plot_mean_coefficients_per_layer_with_plotly(lr_classifier, layers_to_use, output_dir=None):\n",
    "    \"\"\"\n",
    "    Plot the mean coefficient weights per layer for a trained Logistic Regression classifier using Plotly.\n",
    "\n",
    "    Parameters:\n",
    "    - lr_classifier: The trained Logistic Regression classifier.\n",
    "    - layers_to_use: The layers we trained the classifier on\n",
    "    \"\"\"\n",
    "    coefficients = lr_classifier.coef_.flatten()  # Extract model coefficients\n",
    "    print(\"Number of coefficients: {}\".format(len(coefficients)))\n",
    "    total_layers = len(layers_to_use)\n",
    "\n",
    "    # Assuming equal feature contribution from each layer if not specified\n",
    "    features_per_layer = len(coefficients) // total_layers\n",
    "\n",
    "    print(\"Features per layer: {}\".format(features_per_layer))\n",
    "\n",
    "    # Calculate mean coefficient weight per layer\n",
    "    mean_coefficients_per_layer = [np.abs(np.mean(coefficients[i*features_per_layer:(i+1)*features_per_layer])) for i in range(total_layers)]\n",
    "\n",
    "    # Plotting with Plotly\n",
    "    fig = go.Figure(data=[go.Bar(\n",
    "        x=[f'Layer {i}' for i in layers_to_use],\n",
    "        y=mean_coefficients_per_layer,\n",
    "        marker_color=np.where(np.array(mean_coefficients_per_layer) > 0, 'blue', 'red')  # Color code positive and negative\n",
    "    )])\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Mean Coefficient Weights per Layer in Logistic Regression Classifier',\n",
    "        xaxis_title='Layer',\n",
    "        yaxis_title='Mean Coefficient Value',\n",
    "        template='plotly_white'\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    # output to disk if cache_dir is specified\n",
    "    if output_dir:\n",
    "        print(\"Saving figure uwu\")\n",
    "        out_path = os.path.join(output_dir, \"mean_coefficients_per_layer.html\")\n",
    "        fig.write_html(out_path)\n",
    "        print(\"Done -- saved to \", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01ce5505-5d8e-48b2-a8ac-d25fe3cd7789",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_and_split_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load training data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_set, e1_set, e2_set, e3_set \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_split_data\u001b[49m(latent_space_data)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining set size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_set)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE1 set size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(e1_set)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_and_split_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_set, e1_set, e2_set, e3_set = load_and_split_data(latent_space_data)\n",
    "\n",
    "print(f\"Training set size: {len(train_set)}\")\n",
    "print(f\"E1 set size: {len(e1_set)}\")\n",
    "print(f\"E2 set size: {len(e2_set)}\")\n",
    "print(f\"E3 set size: {len(e3_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e888624-e3f2-4c51-a0ef-3c6482b8cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data, extract features, normalize, PCA, etc.\n",
    "\n",
    "# Drop/only use certain layers\n",
    "#layers_to_use = [0,4,7,9,11] \n",
    "layers_to_use = list(range(0,TOTAL_LAYERS))\n",
    "\n",
    "# Preprocess features (normalize and optionally apply PCA) for the training set\n",
    "train_features, train_labels = extract_features_labels(train_set, layers_to_use)\n",
    "train_preprocessed_features, mean_norm, scale_norm, pca_model = preprocess_features(train_features, use_pca=USE_PCA)\n",
    "\n",
    "# Preprocess features for E1 set (if applicable, uncomment and use as needed)\n",
    "e1_features, e1_labels = extract_features_labels(e1_set)\n",
    "e1_preprocessed_features, _, _, _ = preprocess_features(e1_features, mean_norm, scale_norm, pca_model, use_pca=USE_PCA)\n",
    "\n",
    "# Preprocess features for E2 set using the same normalization and PCA model\n",
    "e2_features, e2_labels = extract_features_labels(e2_set, layers_to_use)\n",
    "e2_preprocessed_features, _, _, _ = preprocess_features(e2_features, mean_norm, scale_norm, pca_model, use_pca=USE_PCA)\n",
    "\n",
    "# Preprocess features for E3 set (if applicable, uncomment and use as needed)\n",
    "e3_features, e3_labels = extract_features_labels(e3_set)\n",
    "e3_preprocessed_features, _, _, _ = preprocess_features(e3_features, mean_norm, scale_norm, pca_model, use_pca=USE_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc470a6-7e06-43f3-8670-0f94a56c0bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "lr_classifier = train_lr_classifier(train_preprocessed_features, train_labels)\n",
    "\n",
    "# save weights of lr_classifier in OUTPUT_DIR/weights.npz\n",
    "np.savez(os.path.join(OUTPUT_DIR, \"weights.npz\"), lr_classifier.coef_, lr_classifier.intercept_)\n",
    "\n",
    "# train KNN classifier\n",
    "knn_classifier = train_knn_classifier(train_preprocessed_features, train_labels, n_neighbors=KNN_CLUSTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209db09e-7aca-4db8-a0a3-564efc155ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess Classifier, Save Results\n",
    "\n",
    "print(\"LR Classifier test on E1:\")\n",
    "test_lr_classifier(lr_classifier, e1_preprocessed_features, e1_labels, \n",
    "                   out_path=os.path.join(OUTPUT_DIR, \"lr_classifier_eval_e1.txt\"))\n",
    "\n",
    "print(\"KNN Classifier test on E1:\")\n",
    "test_knn_classifier(knn_classifier, e1_preprocessed_features, e1_labels, \n",
    "                    out_path=os.path.join(OUTPUT_DIR, \"knn_classifier_eval_e1.txt\"))\n",
    "\n",
    "# \n",
    "print(\"LR Classifier test on E2:\")\n",
    "test_lr_classifier(lr_classifier, e2_preprocessed_features, e2_labels, \n",
    "                   out_path=os.path.join(OUTPUT_DIR, \"lr_classifier_eval_e2.txt\"))\n",
    "print(\"KNN Classifier test on E2:\")\n",
    "test_knn_classifier(knn_classifier, e2_preprocessed_features, e2_labels, \n",
    "                    out_path=os.path.join(OUTPUT_DIR, \"knn_classifier_eval_e2.txt\"))\n",
    "\n",
    "print(\"LR Classifier test on E3:\")\n",
    "test_lr_classifier(lr_classifier, e3_preprocessed_features, e3_labels, \n",
    "                    out_path=os.path.join(OUTPUT_DIR, \"lr_classifier_eval_e3.txt\"))\n",
    "print(\"KNN Classifier test on E3:\")\n",
    "test_knn_classifier(knn_classifier, e3_preprocessed_features, e3_labels, \n",
    "                    out_path=os.path.join(OUTPUT_DIR, \"knn_classifier_eval_e3.txt\"))\n",
    "\n",
    "print(\"Combining all output texts with titles into a main results.txt\") \n",
    "with open(os.path.join(OUTPUT_DIR, \"lr_classifier_eval_e1.txt\"), 'r') as f: \n",
    "    e1_text = \"\\n=== E1 LINEAR CLASSIFIER EVAL ===\\n\"\n",
    "    e1_text += f.read()\n",
    "with open(os.path.join(OUTPUT_DIR, \"knn_classifier_eval_e1.txt\"), 'r') as f:\n",
    "    e1_text += \"\\n=== E1 KNN CLASSIFIER EVAL ===\\n\"\n",
    "    e1_text += f.read()\n",
    "with open(os.path.join(OUTPUT_DIR, \"lr_classifier_eval_e2.txt\"), 'r') as f:\n",
    "    e2_text = \"\\n=== E2 LINEAR CLASSIFIER EVAL ===\\n\"\n",
    "    e2_text += f.read()\n",
    "with open(os.path.join(OUTPUT_DIR, \"knn_classifier_eval_e2.txt\"), 'r') as f:\n",
    "    e2_text += \"\\n=== E2 KNN CLASSIFIER EVAL ===\\n\"\n",
    "    e2_text += f.read()\n",
    "with open(os.path.join(OUTPUT_DIR, \"lr_classifier_eval_e3.txt\"), 'r') as f:\n",
    "    e3_text = \"\\n=== E3 LINEAR CLASSIFIER EVAL ===\\n\"\n",
    "    e3_text += f.read()\n",
    "with open(os.path.join(OUTPUT_DIR, \"knn_classifier_eval_e3.txt\"), 'r') as f:\n",
    "    e3_text += \"\\n=== E3 KNN CLASSIFIER EVAL ===\\n\"\n",
    "    e3_text += f.read()\n",
    "\n",
    "use_pca_text = f\"=== USE_PCA = {USE_PCA} ===\\n\"\n",
    "\n",
    "# write e1_text + e2_text + e3_test to a results.txt in the out dir\n",
    "with open(os.path.join(OUTPUT_DIR, \"results.txt\"), 'w') as f:\n",
    "    f.write(use_pca_text + e1_text + e2_text + e3_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e1684-7418-4616-8897-d2c4c9c8c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot/Visualize - dataset, adjectives, latent space, classifier\n",
    "\n",
    "# View the dataset PCA\n",
    "all_features, all_labels = extract_features_labels(latent_space_data)\n",
    "adjectives = [item['adjective'] for item in latent_space_data] # Assuming 'data' is your entire dataset # Optionally, if you want to visualize using specific labels or adjectives\n",
    "prompts = [item['prompt_template'] for item in latent_space_data] # Assuming 'data' is your entire dataset # Optionally, if you want to visualize using specific labels or adjectives\n",
    "\n",
    "all_adjectives = list(set(entry['adjective'] for entry in latent_space_data))\n",
    "all_prompts = list(set(entry['prompt_template'] for entry in latent_space_data))\n",
    "# pdb.set_trace()\n",
    "\n",
    "\n",
    "if PLOT_ALL_DATA:\n",
    "    # all data plot\n",
    "    all_preprocessed_features, _, _, pca_model = preprocess_features(all_features, use_pca = True)\n",
    "    plot_3d_pca(all_preprocessed_features, all_labels, adjectives=adjectives, output_dir = OUTPUT_DIR, prompt=\"ALL PROMPTS\")\n",
    "    for prompt in all_prompts: \n",
    "        prompt_mask = [item['prompt_template'] == prompt for item in latent_space_data]\n",
    "\n",
    "        # pdb.set_trace()\n",
    "        all_features_filtered = all_features[prompt_mask, :]\n",
    "        all_labels_filtered = all_labels[prompt_mask]\n",
    "        all_preprocessed_features, _, _, pca_model = preprocess_features(all_features_filtered, use_pca = True)\n",
    "        # pdb.set_trace()\n",
    "        plot_3d_pca(all_preprocessed_features, all_labels_filtered, adjectives=np.array(adjectives)[prompt_mask].tolist(), output_dir = OUTPUT_DIR, prompt=prompt)\n",
    "\n",
    "# View the linear regression classifier coefficients per layer (only makes sense to do if we haven't PCA'ed)\n",
    "if not USE_PCA and PLOT_LR:\n",
    "    plot_mean_coefficients_per_layer_with_plotly(lr_classifier, layers_to_use, output_dir = OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32799dbb-4e4e-4b5d-a50d-e234c005e9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nudge the latent space\n",
    "\n",
    "def adjust_feature_vector(feature_vector, lr_classifier, layers_to_use, step_size=0.01):\n",
    "    \"\"\"\n",
    "    Adjusts the feature vector towards a specific class using the logistic regression classifier coefficients.\n",
    "\n",
    "    Parameters:\n",
    "    - feature_vector: The original feature vector to adjust.\n",
    "    - lr_classifier: The trained logistic regression classifier.\n",
    "    - layers_to_use: List of integers specifying which transformer layers were used.\n",
    "    - step_size: The magnitude of the adjustment step (default: 0.01).\n",
    "\n",
    "    Returns:\n",
    "    - adjusted_feature_vector: The adjusted feature vector.\n",
    "    \"\"\"\n",
    "    # Extract the logistic regression coefficients\n",
    "    coefficients = lr_classifier.coef_[0]\n",
    "\n",
    "    # Calculate the total number of features per layer\n",
    "    total_features = len(coefficients) // len(layers_to_use)\n",
    "\n",
    "    # Adjust the feature vector\n",
    "    adjusted_feature_vector = feature_vector.copy()\n",
    "    for i, layer_idx in enumerate(layers_to_use):\n",
    "        start_idx = i * total_features\n",
    "        end_idx = (i+1) * total_features\n",
    "        # Adjust features for the current layer based on the coefficients\n",
    "        adjusted_feature_vector[start_idx:end_idx] += coefficients[start_idx:end_idx] * step_size\n",
    "    \n",
    "    return adjusted_feature_vector\n",
    "\n",
    "def get_tokenizer_and_model(model_name): \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name).to('cuda')\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "def get_bob_vals(past_kvs): \n",
    "    \"\"\"\n",
    "    Args: \n",
    "        `past_kvs`: model output['past_key_values'] from running a batch of \n",
    "        left-padded sentences through the model.\n",
    "\n",
    "        Accepts `past_kvs`, a tuple of length NUM_LAYERS (32), each containing a \n",
    "        2-long tuple (for keys and values respectively), each containing a torch \n",
    "        Tensor of shape [batch, num_heads, seq_len, head_dim] (for values). \n",
    "\n",
    "    Returns: \n",
    "        `bob_kvs`: list of length BATCH_SIZE with some numpy arrays representing \n",
    "        of shape [num_layers, num_heads, head_dim]\n",
    "    \"\"\"\n",
    "\n",
    "    # iterate thru batch size \n",
    "    BATCH_SIZE = past_kvs[0][1].shape[0]\n",
    "\n",
    "    batch_bob_values = []\n",
    "    for batch_el in range(BATCH_SIZE): \n",
    "        # aggregate representations from across the layers \n",
    "        bob_numpy_arrays = []\n",
    "        for layer in range(len(past_kvs)): \n",
    "            bob_layer_l_value = past_kvs[layer][1][batch_el, :, -1, :].detach().cpu().numpy()\n",
    "            # print(\"Bob layer_l_value shape: \", bob_layer_l_value.shape)\n",
    "\n",
    "            # unsqueeze on dimension zero\n",
    "            bob_numpy_arrays.append(bob_layer_l_value[np.newaxis, ...])\n",
    "        \n",
    "        # merge on axis 0\n",
    "        bob_numpy_arrays_conc = np.concatenate(bob_numpy_arrays, axis=0)\n",
    "        # print(\"Bob numpy arrays shape (post-concatenation to combine layers)\", bob_numpy_arrays_conc.shape)\n",
    "        # bob_numpy_arrays now has shape n_layers = 32, n_heads = 8, embed_dim=128\n",
    "\n",
    "        # add it to the list\n",
    "        batch_bob_values.append(bob_numpy_arrays_conc)\n",
    "\n",
    "\n",
    "    return batch_bob_values\n",
    "\n",
    "def get_latent_space(full_prompt_list, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Generate value representations for prompts.\n",
    "\n",
    "    Args:\n",
    "        full_prompt_list: Full list of prompts.\n",
    "        model: Hugging Face model.\n",
    "        tokenizer: Hugging Face tokenizer.\n",
    "\n",
    "    Returns:\n",
    "        list: Full list of prompts with value representations. \n",
    "              This will ALWAYS be the representation of the final token. \n",
    "    \"\"\"\n",
    "    final_prompt_list = []\n",
    "    for i in tqdm(range(len(full_prompt_list))):\n",
    "        prompt_ids_i = full_prompt_list[i]['final_prompt_ids'] # 1-dim list\n",
    "        # make into 2-dim tensor\n",
    "        prompt_ids_i = torch.tensor(prompt_ids_i).unsqueeze(0).to(model.device)\n",
    "        # check that the final token is the token of interest\n",
    "        assert tokenizer.decode(prompt_ids_i[0, -1]) == full_prompt_list[i]['token_of_interest']\n",
    "        # get the hidden states\n",
    "        outputs = model.forward(prompt_ids_i, return_dict=True)\n",
    "        past_kv = outputs['past_key_values']\n",
    "        # past_kv is a tuple of length num_layers\n",
    "        # past_kv[0] is a tuple of length 2 (keys, values)\n",
    "        # past_kv[0][1] is a tensor of shape [batch=1, num_heads=12, num_tokens, dim_head=64]\n",
    "        #  --> num_heads * dim_head = 12*64 = d_model = 768\n",
    "        bob_reps = get_bob_vals(past_kv)\n",
    "        assert len(bob_reps) == 1\n",
    "        final_prompt_list.append(full_prompt_list[i])\n",
    "        final_prompt_list[-1]['latent_space'] = bob_reps[0]\n",
    "    return final_prompt_list\n",
    "\n",
    "def np_to_lists(final_prompt_list): \n",
    "    \"\"\" Convert each final_prompt_list[i]['latent_space'] from a list of numpy arrays to a list of lists.\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(len(final_prompt_list))): \n",
    "        final_prompt_list[i]['latent_space'] = final_prompt_list[i]['latent_space'].tolist()\n",
    "    return final_prompt_list\n",
    "\n",
    "def main(args):\n",
    "    print(f\"\\nLoading tokenizer and model `{args.model_name}`...\")\n",
    "    tokenizer, model = get_tokenizer_and_model(args)\n",
    "    print(\"Done!\\n\")\n",
    "\n",
    "    # ensure output path doesn't exist. prompt the user if it does \n",
    "    if os.path.exists(args.out_path):\n",
    "        print(f\"\\nOutput path {args.out_path} already exists. Overwrite? (y/n) \")\n",
    "        if input().lower() != 'y':\n",
    "            print(\"Exiting...\")\n",
    "            return\n",
    "\n",
    "    print(\"\\nGenerating combined prompt list from adjectives * prompt templates...\")\n",
    "    full_prompt_list = get_full_prompt_list(args, tokenizer)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    # get value representations\n",
    "    print(\"\\nGetting value representations of final tokens...\")\n",
    "    final_prompt_list = get_latent_space(full_prompt_list, model, tokenizer)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    # convert numpy arrays to lists\n",
    "    print(\"\\nConverting numpy arrays to lists...\")\n",
    "    final_prompt_list = np_to_lists(final_prompt_list)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    # save to file\n",
    "    print(\"\\nSaving to file...\")\n",
    "    with open(args.out_path, 'w') as f:\n",
    "        json.dump(final_prompt_list, f, indent=4)\n",
    "    print(\"Done! Thank you for shopping at the Language Game!\")\n",
    "\n",
    "\n",
    "# spin up GPT2\n",
    "tokenizer, model = get_tokenizer_and_model(MODEL_NAME)\n",
    "\n",
    "# select a feature vector to mess with\n",
    "# select random row from latent_space_data\n",
    "# run that single row through extract_feature_labels()\n",
    "# fv_to_test =\n",
    "\n",
    "# push feature vector continually more and more in the direction we choose\n",
    "num_steps = 100\n",
    "step_size = 0.01\n",
    "for i in num_steps:\n",
    "    # Adjust a feature vector towards the favored class\n",
    "    fv_to_test = adjust_feature_vector(fv_to_test, lr_classifier, layers_to_use, step_size=step_size)\n",
    "\n",
    "    # Inject the new adjusted feature vector into GPT2 here\n",
    "    # use an inject version of get_value_reps.py\n",
    "\n",
    "    # Generate the next 3 tokens to see if they went in the direction that we want OR just look at the probability distribu\n",
    "    # genereate with GPT2 here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
